//! C++ Backend for CPU Simulation
//!
//! This module provides a thin wrapper around SharedCodegen that generates
//! standard C++ code for compiled CPU simulation. The generated code can be
//! compiled with any C++14 compatible compiler (clang++, g++, MSVC).
//!
//! # Generated Code Structure
//!
//! - Type aliases to match Metal (`uint` -> `uint32_t`)
//! - Identical struct layouts for Inputs, Registers, Signals
//! - `extern "C"` functions for dlopen/dlsym loading
//! - Export table with function pointers and buffer sizes

use crate::sir::SirModule;

use super::shared::SharedCodegen;
use super::types::BackendTarget;

/// C++ backend for compiled CPU simulation
pub struct CppBackend<'a> {
    shared: SharedCodegen<'a>,
}

impl<'a> CppBackend<'a> {
    /// Create a new C++ backend for the given SIR module
    pub fn new(module: &'a SirModule) -> Self {
        Self {
            shared: SharedCodegen::new(module, BackendTarget::Cpp),
        }
    }

    /// Generate complete C++ source code
    pub fn generate(module: &SirModule) -> String {
        let mut backend = CppBackend::new(module);
        backend.generate_source()
    }

    /// Generate the complete C++ source
    fn generate_source(&mut self) -> String {
        let mut output = String::new();

        // C++ header with type aliases matching Metal
        output.push_str(
            r#"// Generated by Skalp Compiler - C++ Backend
// This file is auto-generated. Do not edit.

#include <stdint.h>
#include <string.h>
#include <math.h>

// Type aliases to match Metal Shading Language
using uint = uint32_t;
using ulong = uint64_t;

// Vector types (simplified - just arrays for CPU)
struct uint2 { uint x, y; };
struct uint3 { uint x, y, z; };
struct uint4 { uint x, y, z, w; };
struct float2 { float x, y; };
struct float3 { float x, y, z; };
struct float4 { float x, y, z, w; };

// FP16 conversion helpers (IEEE 754 half-precision)
static inline float _fp16_to_fp32(uint32_t h) {
    uint32_t sign = (h & 0x8000) << 16;
    uint32_t exp = (h >> 10) & 0x1F;
    uint32_t mant = h & 0x3FF;

    if (exp == 0) {
        // Denormalized or zero
        if (mant == 0) {
            // Zero
            return *(float*)&sign;
        } else {
            // Denormalized: convert to normalized
            while (!(mant & 0x400)) {
                mant <<= 1;
                exp--;
            }
            exp++;
            mant &= 0x3FF;
            exp = exp + (127 - 15);
            uint32_t result = sign | (exp << 23) | (mant << 13);
            return *(float*)&result;
        }
    } else if (exp == 31) {
        // Inf or NaN
        uint32_t result = sign | 0x7F800000 | (mant << 13);
        return *(float*)&result;
    } else {
        // Normalized
        exp = exp + (127 - 15);
        uint32_t result = sign | (exp << 23) | (mant << 13);
        return *(float*)&result;
    }
}

static inline uint32_t _fp32_to_fp16(float f) {
    uint32_t x = *(uint32_t*)&f;
    uint32_t sign = (x >> 16) & 0x8000;
    int32_t exp = ((x >> 23) & 0xFF) - 127 + 15;
    uint32_t mant = x & 0x7FFFFF;

    if (exp <= 0) {
        // Underflow to zero or denormalized
        if (exp < -10) {
            return sign; // Zero
        }
        // Denormalized
        mant = (mant | 0x800000) >> (1 - exp);
        return sign | (mant >> 13);
    } else if (exp >= 31) {
        // Overflow to infinity or NaN
        if (exp == 31 && mant != 0) {
            return sign | 0x7C00 | (mant >> 13); // NaN
        }
        return sign | 0x7C00; // Infinity
    } else {
        // Normalized
        return sign | (exp << 10) | (mant >> 13);
    }
}

"#,
        );

        // Generate struct definitions using shared codegen
        self.shared.generate_inputs_struct();
        self.shared.generate_registers_struct();
        self.shared.generate_signals_struct();
        output.push_str(&self.shared.take_output());

        // Generate combinational evaluation function
        output.push_str(&self.generate_combinational_function());

        // Generate sequential update function
        output.push_str(&self.generate_sequential_function());

        // Generate batched simulation function
        output.push_str(&self.generate_batched_function());

        // Generate export table
        output.push_str(&self.generate_export_table());

        output
    }

    /// Generate the combinational evaluation function
    fn generate_combinational_function(&mut self) -> String {
        let mut output = String::new();

        output.push_str(
            r#"// Combinational logic evaluation
extern "C" void combinational_eval(
    const Inputs* inputs,
    const Registers* registers,
    Signals* signals
) {
"#,
        );

        // Generate combinational body using shared codegen
        self.shared.indent();
        self.shared.generate_combinational_body();
        output.push_str(&self.shared.take_output());

        output.push_str("}\n\n");
        output
    }

    /// Generate the sequential update function
    fn generate_sequential_function(&mut self) -> String {
        let mut output = String::new();

        output.push_str(
            r#"// Sequential (flip-flop) update
extern "C" void sequential_update(
    const Inputs* inputs,
    const Registers* current_registers,
    const Signals* signals,
    Registers* next_registers
) {
"#,
        );

        // Generate sequential body using shared codegen
        self.shared.indent();
        self.shared
            .generate_sequential_body("current_registers", "next_registers");
        output.push_str(&self.shared.take_output());

        output.push_str("}\n\n");
        output
    }

    /// Generate the batched simulation function
    fn generate_batched_function(&mut self) -> String {
        let mut output = String::new();

        output.push_str(
            r#"// Batched simulation for multiple cycles
extern "C" void batched_simulation(
    Inputs* inputs,
    Registers* registers,
    Signals* signals,
    uint32_t num_cycles
) {
"#,
        );

        // Generate local variables for scalar state elements
        self.generate_local_state_copies(&mut output);

        // Main simulation loop
        output.push_str("    for (uint32_t cycle = 0; cycle < num_cycles; cycle++) {\n");

        // Combinational evaluation
        self.shared.set_batched_mode(true);
        self.shared.indent();
        self.shared.indent();
        self.shared.generate_combinational_body();
        output.push_str(&self.shared.take_output());

        // Sequential updates
        self.shared
            .generate_sequential_body("registers", "registers");
        output.push_str(&self.shared.take_output());
        self.shared.set_batched_mode(false);
        self.shared.dedent();

        output.push_str("    }\n");

        // Copy local state back to registers
        self.generate_local_state_writeback(&mut output);

        // Final combinational pass: propagate updated register values to output signals
        // Without this, output signals are stale by one cycle (reflect pre-update state)
        output.push_str(
            "\n    // Final combinational pass (FWFT: outputs reflect latest register state)\n",
        );
        self.shared.generate_combinational_body();
        output.push_str(&self.shared.take_output());

        output.push_str("}\n\n");
        output
    }

    /// Generate local copies of scalar state elements for batched mode
    fn generate_local_state_copies(&self, output: &mut String) {
        use crate::sir::{SirNodeKind, SirType};
        use std::collections::HashSet;

        let mut sorted_states: Vec<_> = self.shared.module.state_elements.iter().collect();
        sorted_states.sort_by_key(|(name, _)| *name);

        let mut declared_locals: HashSet<String> = HashSet::new();

        for (name, elem) in &sorted_states {
            // Skip array-type state elements (use sir_type or width-based detection)
            let signal_width = self.shared.get_signal_width(name);
            let is_array = if let Some(ref sir_type) = elem.sir_type {
                matches!(sir_type, SirType::Array(_, _))
            } else {
                // Fall back to width-based check
                let (_, array_size) = self.shared.type_mapper.get_type_for_width(signal_width);
                array_size.is_some()
            };

            if is_array {
                continue; // Arrays don't get local copies
            }

            // Only create local copies for scalar registers (â‰¤64 bits for C++)
            if signal_width <= 64 {
                let sanitized = self.shared.sanitize_name(name);
                let (base_type, array_size) =
                    self.shared.type_mapper.get_type_for_width(signal_width);

                if array_size.is_none() {
                    output.push_str(&format!(
                        "    {} local_{} = registers->{};\n",
                        base_type, sanitized, sanitized
                    ));
                    declared_locals.insert(sanitized);
                }
            }
        }

        // BUG #254 FIX: Also declare local variables for FF outputs not in state_elements
        // These are needed because the batched kernel uses local variables for all register values
        for node in &self.shared.module.sequential_nodes {
            if let SirNodeKind::FlipFlop { .. } = &node.kind {
                for ff_output in &node.outputs {
                    if !self
                        .shared
                        .module
                        .state_elements
                        .contains_key(&ff_output.signal_id)
                    {
                        let sanitized = self.shared.sanitize_name(&ff_output.signal_id);
                        if declared_locals.contains(&sanitized) {
                            continue;
                        }
                        let width = self.shared.get_signal_width(&ff_output.signal_id);
                        if width <= 64 {
                            let (base_type, array_size) =
                                self.shared.type_mapper.get_type_for_width(width);
                            if array_size.is_none() {
                                output.push_str(&format!(
                                    "    {} local_{} = registers->{};\n",
                                    base_type, sanitized, sanitized
                                ));
                                declared_locals.insert(sanitized);
                            }
                        }
                    }
                }
            }
        }

        output.push('\n');
    }

    /// Generate writeback of local state to registers after batched simulation
    fn generate_local_state_writeback(&self, output: &mut String) {
        use crate::sir::{SirNodeKind, SirType};
        use std::collections::HashSet;

        let mut sorted_states: Vec<_> = self.shared.module.state_elements.iter().collect();
        sorted_states.sort_by_key(|(name, _)| *name);

        let mut written_back: HashSet<String> = HashSet::new();

        output.push_str("\n    // Write back local state to registers\n");
        for (name, elem) in &sorted_states {
            // Skip array-type state elements
            let is_array = if let Some(ref sir_type) = elem.sir_type {
                matches!(sir_type, SirType::Array(_, _))
            } else {
                false
            };

            if is_array {
                continue; // Arrays are written directly, not via local copies
            }

            if elem.width <= 64 {
                let sanitized = self.shared.sanitize_name(name);
                let (_, array_size) = self.shared.type_mapper.get_type_for_width(elem.width);

                if array_size.is_none() {
                    output.push_str(&format!(
                        "    registers->{} = local_{};\n",
                        sanitized, sanitized
                    ));
                    written_back.insert(sanitized);
                }
            }
        }

        // BUG #254 FIX: Also write back FF outputs not in state_elements
        for node in &self.shared.module.sequential_nodes {
            if let SirNodeKind::FlipFlop { .. } = &node.kind {
                for ff_output in &node.outputs {
                    if !self
                        .shared
                        .module
                        .state_elements
                        .contains_key(&ff_output.signal_id)
                    {
                        let sanitized = self.shared.sanitize_name(&ff_output.signal_id);
                        if written_back.contains(&sanitized) {
                            continue;
                        }
                        let width = self.shared.get_signal_width(&ff_output.signal_id);
                        if width <= 64 {
                            let (_, array_size) = self.shared.type_mapper.get_type_for_width(width);
                            if array_size.is_none() {
                                output.push_str(&format!(
                                    "    registers->{} = local_{};\n",
                                    sanitized, sanitized
                                ));
                                written_back.insert(sanitized);
                            }
                        }
                    }
                }
            }
        }
    }

    /// Generate the export table for dynamic loading
    fn generate_export_table(&mut self) -> String {
        r#"// Export table for dynamic loading
struct SkalpKernel {
    void (*combinational_eval)(const Inputs*, const Registers*, Signals*);
    void (*sequential_update)(const Inputs*, const Registers*, const Signals*, Registers*);
    void (*batched_simulation)(Inputs*, Registers*, Signals*, uint32_t);
    size_t inputs_size;
    size_t registers_size;
    size_t signals_size;
};

extern "C" const SkalpKernel SKALP_KERNEL = {
    combinational_eval,
    sequential_update,
    batched_simulation,
    sizeof(Inputs),
    sizeof(Registers),
    sizeof(Signals)
};
"#
        .to_string()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_cpp_backend_creation() {
        // Create a minimal SIR module for testing
        let module = SirModule {
            name: "test".to_string(),
            inputs: vec![],
            outputs: vec![],
            signals: vec![],
            combinational_nodes: vec![],
            sequential_nodes: vec![],
            state_elements: Default::default(),
            clock_domains: Default::default(),
            sorted_combinational_node_ids: vec![],
            pipeline_config: None,
            span: None,
            name_registry: Default::default(),
        };

        let source = CppBackend::generate(&module);
        assert!(source.contains("using uint = uint32_t"));
        assert!(source.contains("extern \"C\" void combinational_eval"));
        assert!(source.contains("extern \"C\" void sequential_update"));
        assert!(source.contains("extern \"C\" void batched_simulation"));
        assert!(source.contains("SKALP_KERNEL"));
    }

    #[test]
    fn test_cpp_type_aliases() {
        let module = SirModule {
            name: "test".to_string(),
            inputs: vec![],
            outputs: vec![],
            signals: vec![],
            combinational_nodes: vec![],
            sequential_nodes: vec![],
            state_elements: Default::default(),
            clock_domains: Default::default(),
            sorted_combinational_node_ids: vec![],
            pipeline_config: None,
            span: None,
            name_registry: Default::default(),
        };

        let source = CppBackend::generate(&module);
        // Verify type aliases are present
        assert!(source.contains("using uint = uint32_t"));
        assert!(source.contains("using ulong = uint64_t"));
        assert!(source.contains("struct uint2"));
        assert!(source.contains("struct uint4"));
    }
}
